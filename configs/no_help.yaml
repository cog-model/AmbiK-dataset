experiment: 
    examples_generation:
        model: "gpt-3.5-turbo"
        #"NousResearch/Llama-2-7b-chat-hf"
        #"google/gemma-7b"
        generation_kwargs:
            max_tokens: 256
            stop: ['We:']
            logprobs: False
            logit_bias: {}